[
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Deploy the new application version using 'Rolling' deployment policy"
                },
                {
                    "id": 2,
                    "value": "Deploy the new application version using 'Rolling with additional batch' deployment policy"
                },
                {
                    "id": 3,
                    "value": "Deploy the new application version using 'All at once' deployment policy"
                },
                {
                    "id": 4,
                    "value": "Deploy the new application version using 'Immutable' deployment policy"
                }
            ],
            "question1": "The development team at an e-commerce company completed the last deployment for their application at a reduced capacity because of the deployment policy. The application took a performance hit because of the traffic spike due to an on-going sale.",
            "question2": "Which of the following represents the BEST deployment option for the upcoming application version such that it maintains at least the FULL capacity of the application and MINIMAL impact of failed deployment?"
        },
        "answers": [
            4
        ],
        "id": 1
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Use Change Sets feature of CloudFormation"
                },
                {
                    "id": 2,
                    "value": "Use CloudFormation in Elastic Beanstalk environment to reduce direct changes to CloudFormation resources"
                },
                {
                    "id": 3,
                    "value": "Use Drift Detection feature of CloudFormation"
                },
                {
                    "id": 4,
                    "value": "Use Tag feature of CloudFormation to monitor the changes happening on specific resources"
                }
            ],
            "question1": "An e-commerce company uses AWS CloudFormation to implement Infrastructure as Code for the entire organization. Maintaining resources as stacks with CloudFormation has greatly reduced the management effort needed to manage and maintain the resources. However, a few teams have been complaining of failing stack updates owing to out-of-band fixes running on the stack resources.",
            "question2": "Which of the following is the best solution that can help in keeping the CloudFormation stack and its resources in sync with each other?"
        },
        "answers": [
            3
        ],
        "id": 2
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Bundle the dependencies in the source code during the build stage of CodeBuild"
                },
                {
                    "id": 2,
                    "value": "Store the dependencies in S3, to be used while deploying to Beanstalk"
                },
                {
                    "id": 3,
                    "value": "Bundle the dependencies in the source code in CodeCommit"
                },
                {
                    "id": 4,
                    "value": "Create a custom platform for Elastic Beanstalk"
                }
            ],
            "question1": "You have created a continuous delivery service model with automated steps using AWS CodePipeline. Your pipeline uses your code, maintained in a CodeCommit repository, AWS CodeBuild, and AWS Elastic Beanstalk to automatically deploy your code every time there is a code change. However, the deployment to Elastic Beanstalk is taking a very long time due to resolving dependencies on all of your 100 target EC2 instances.",
            "question2": "Which of the following actions should you take to improve performance with limited code changes?"
        },
        "answers": [
            1
        ],
        "id": 3
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "The required IAM permissions are missing"
                },
                {
                    "id": 2,
                    "value": "The EBS volume is encrypted"
                },
                {
                    "id": 3,
                    "value": "EBS volumes are AZ locked"
                },
                {
                    "id": 4,
                    "value": "EBS volumes are region locked"
                }
            ],
            "question1": "A developer with access to the AWS Management Console terminated an instance in the us-east-1a availability zone. The attached EBS volume remained and is now available for attachment to other instances. Your colleague launches a new Linux EC2 instance in the us-east-1e availability zone and is attempting to attach the EBS volume. Your colleague informs you that it is not possible and need your help.",
            "question2": "Which of the following explanations would you provide to them?"
        },
        "answers": [
            3
        ],
        "id": 4
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Configure VPC endpoints for DynamoDB that will provide required internal access without using public internet"
                },
                {
                    "id": 2,
                    "value": "Create an Internet Gateway to provide the necessary communication channel between EC2 instances and DynamoDB"
                },
                {
                    "id": 3,
                    "value": "Create a NAT Gateway to provide the necessary communication channel between EC2 instances and DynamoDB"
                },
                {
                    "id": 4,
                    "value": "The firm can use a virtual private network (VPN) to route all DynamoDB network traffic through their own corporate network infrastructure"
                }
            ],
            "question1": "A CRM application is hosted on Amazon EC2 instances with the database tier using DynamoDB. The customers have raised privacy and security concerns regarding sending and receiving data across the public internet.",
            "question2": "As a developer associate, which of the following would you suggest as an optimal solution for providing communication between EC2 instances and DynamoDB without using the public internet?"
        },
        "answers": [
            1
        ],
        "id": 5
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "ALBRequestCountPerTarget"
                },
                {
                    "id": 2,
                    "value": "ASGAverageNetworkOut"
                },
                {
                    "id": 3,
                    "value": "ASGAverageCPUUtilization"
                },
                {
                    "id": 4,
                    "value": "ApproximateNumberOfMessagesVisible"
                }
            ],
            "question1": "A Developer is configuring Amazon EC2 Auto Scaling group to scale dynamically.",
            "question2": "Which metric below is NOT part of Target Tracking Scaling Policy?"
        },
        "answers": [
            4
        ],
        "id": 6
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "All instances are charged at one hour of On-Demand Instance usage"
                },
                {
                    "id": 2,
                    "value": "One instance is charged at one hour of On-Demand usage and the other two instances are charged at two hours of Reserved Instance usage"
                },
                {
                    "id": 3,
                    "value": "All instances are charged at one hour of Reserved Instance usage"
                },
                {
                    "id": 4,
                    "value": "One instance is charged at one hour of Reserved Instance usage and the other two instances are charged at two hours of On-Demand usage"
                }
            ],
            "question1": "A business has purchased one m4.xlarge Reserved Instance but it has used three m4.xlarge instances concurrently for an hour.",
            "question2": "As a Developer, explain how the instances are charged?"
        },
        "answers": [
            4
        ],
        "id": 7
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Implement a Dead-Letter Queue"
                },
                {
                    "id": 2,
                    "value": "Reduce the VisibilityTimeout"
                },
                {
                    "id": 3,
                    "value": "Increase the VisibilityTimeout"
                },
                {
                    "id": 4,
                    "value": "Use DeleteMessage"
                }
            ],
            "question1": "An application running on EC2 instances processes messages from an SQS queue. However, sometimes the messages are not processed and they end up in errors. These messages need to be isolated for further processing and troubleshooting.",
            "question2": "Which of the following options will help achieve this?"
        },
        "answers": [
            1
        ],
        "id": 8
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "The second statement in this policy provides the security group (mentioned in first statement of the policy), the ability to create, list, and revoke grants for Amazon EC2"
                },
                {
                    "id": 2,
                    "value": "The first statement provides the security group the ability to generate a data key and decrypt that data key from the CMK when necessary"
                },
                {
                    "id": 3,
                    "value": "The first statement provides a specified IAM principal the ability to generate a data key and decrypt that data key from the CMK when necessary"
                },
                {
                    "id": 4,
                    "value": "The second statement in the policy mentions that all the resources stated in the first statement can take the specified role which will provide the ability to create, list, and revoke grants for Amazon EC2"
                }
            ],
            "question1": "An Accounting firm extensively uses Amazon EBS volumes for persistent storage of application data of Amazon EC2 instances. The volumes are encrypted to protect the critical data of the clients. As part of managing the security credentials, the project manager has come across a policy snippet that looks like the following:",
            "question2": "{",
            "question3": "    \"Version\": \"2012-10-17\",",
            "question4": "    \"Statement\": [",
            "question5": "        {",
            "question6": "            \"Sid\": \"Allow for use of this Key\",",
            "question7": "            \"Effect\": \"Allow\",",
            "question8": "            \"Principal\": {",
            "question9": "                \"AWS\": \"arn:aws:iam::111122223333:role/UserRole\"",
            "question10": "            },",
            "question11": "            \"Action\": [",
            "question12": "                \"kms:GenerateDataKeyWithoutPlaintext\",",
            "question13": "                \"kms:Decrypt\"",
            "question14": "            ],",
            "question15": "            \"Resource\": \"*\"",
            "question16": "        },",
            "question17": "        {",
            "question18": "            \"Sid\": \"Allow for EC2 Use\",",
            "question19": "            \"Effect\": \"Allow\",",
            "question20": "            \"Principal\": {",
            "question21": "                \"AWS\": \"arn:aws:iam::111122223333:role/UserRole\"",
            "question22": "            },",
            "question23": "            \"Action\": [",
            "question24": "                \"kms:CreateGrant\",",
            "question25": "                \"kms:ListGrants\",",
            "question26": "                \"kms:RevokeGrant\"",
            "question27": "            ],",
            "question28": "            \"Resource\": \"*\",",
            "question29": "            \"Condition\": {",
            "question30": "                \"StringEquals\": {",
            "question31": "                \"kms:ViaService\": \"ec2.us-west-2.amazonaws.com\"",
            "question32": "            }",
            "question33": "        }",
            "question34": "    ]",
            "question35": "}"
        },
        "answers": [
            3
        ],
        "id": 9
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Create an IAM role (instance profile) in Account A and set Account B as a trusted entity. Attach this role to the EC2 instances in Account A and add an inline policy to this role to access S3 data from Account B"
                },
                {
                    "id": 2,
                    "value": "Create an IAM role with S3 access in Account B and set Account A as a trusted entity. Create another role (instance profile) in Account A and attach it to the EC2 instances in Account A and add an inline policy to this role to assume the role from Account B"
                },
                {
                    "id": 3,
                    "value": "Copy the underlying AMI for the EC2 instances from Account A into Account B. Launch EC2 instances in Account B using this AMI and then access the PII data on Amazon S3 in Account B"
                },
                {
                    "id": 4,
                    "value": "Add a bucket policy to all the Amazon S3 buckets in Account B to allow access from EC2 instances in Account A"
                }
            ],
            "question1": "The development team at a HealthCare company has deployed EC2 instances in AWS Account A. These instances need to access patient data with Personally Identifiable Information (PII) on multiple S3 buckets in another AWS Account B.",
            "question2": "As a Developer Associate, which of the following solutions would you recommend for the given use-case?"
        },
        "answers": [
            2
        ],
        "id": 10
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "The instance's subnet is associated with multiple route tables with conflicting configurations"
                },
                {
                    "id": 2,
                    "value": "The network ACLs associated with the subnet must have rules to allow inbound and outbound traffic"
                },
                {
                    "id": 3,
                    "value": "The subnet has been configured to be Public and has no access to the internet"
                },
                {
                    "id": 4,
                    "value": "The route table in the instanceï¿½s subnet should have a route to an Internet Gateway"
                },
                {
                    "id": 5,
                    "value": "The instance's subnet is not associated with any route table"
                }
            ],
            "question1": "While troubleshooting, a developer realized that the Amazon EC2 instance is unable to connect to the Internet using the Internet Gateway.",
            "question2": "Which conditions should be met for Internet connectivity to be established? (Select two)"
        },
        "answers": [
            2,
            4
        ],
        "id": 11
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Stack C then Stack A then Stack B"
                },
                {
                    "id": 2,
                    "value": "Stack A, Stack C then Stack B"
                },
                {
                    "id": 3,
                    "value": "Stack B, then Stack C, then Stack A"
                },
                {
                    "id": 4,
                    "value": "Stack A, then Stack B, then Stack C"
                }
            ],
            "question1": "As an AWS certified developer associate, you are working on an AWS CloudFormation template that will create resources for a company's cloud infrastructure. Your template is composed of three stacks which are Stack-A, Stack-B, and Stack-C. Stack-A will provision a VPC, a security group, and subnets for public web applications that will be referenced in Stack-B and Stack-C.",
            "question2": "After running the stacks you decide to delete them, in which order should you do it?"
        },
        "answers": [
            3
        ],
        "id": 12
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "It is not possible to reuse SSH key pairs across AWS Regions"
                },
                {
                    "id": 2,
                    "value": "Store the public and private SSH key pair in AWS Trusted Advisor and access it across AWS Regions"
                },
                {
                    "id": 3,
                    "value": "Encrypt the private SSH key and store it in the S3 bucket to be accessed from any AWS Region"
                },
                {
                    "id": 4,
                    "value": "Generate a public SSH key from a private SSH key. Then, import the key into each of your AWS Regions"
                }
            ],
            "question1": "A company runs its flagship application on a fleet of Amazon EC2 instances. After misplacing a couple of private keys from the SSH key pairs, they have decided to re-use their SSH key pairs for the different instances across AWS Regions.",
            "question2": "As a Developer Associate, which of the following would you recommend to address this use-case?"
        },
        "answers": [
            4
        ],
        "id": 13
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Erroneous Bucket policies for batch uploads can sometimes be responsible for the exponential growth of S3 Bucket size"
                },
                {
                    "id": 2,
                    "value": "Object Encryption has been enabled and each object is stored twice as part of this configuration"
                },
                {
                    "id": 3,
                    "value": "S3 access logging is pointing to the same bucket and is responsible for the substantial growth of bucket size"
                },
                {
                    "id": 4,
                    "value": "A DDoS attack on your S3 bucket can potentially blow up the size of data in the bucket if the bucket security is compromised during the attack"
                }
            ],
            "question1": "A company has created an Amazon S3 bucket that holds customer data. The team lead has just enabled access logging to this bucket. The bucket size has grown substantially after starting access logging. Since no new files have been added to the bucket, the perplexed team lead is looking for an answer.",
            "question2": "Which of the following reasons explains this behavior?"
        },
        "answers": [
            3
        ],
        "id": 14
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "\"HelloWorld\": { \"Type\": \"Task\", \"Resource\": \"arn:aws:lambda:us-east-1:123456789012:function:HelloFunction\", \"Next\": \"AfterHelloWorldState\", \"Comment\": \"Run the HelloWorld Lambda function\" }"
                },
                {
                    "id": 2,
                    "value": "\"wait_until\" : { \"Type\": \"Wait\", \"Timestamp\": \"2016-03-14T01:59:00Z\", \"Next\": \"NextState\" }"
                },
                {
                    "id": 3,
                    "value": "\"No-op\": { \"Type\": \"Task\", \"Result\": { \"x-datum\": 0.381018, \"y-datum\": 622.2269926397355 }, \"ResultPath\": \"$.coords\", \"Next\": \"End\" }"
                },
                {
                    "id": 4,
                    "value": "\"FailState\": { \"Type\": \"Fail\", \"Cause\": \"Invalid response.\", \"Error\": \"ErrorA\" }"
                }
            ],
            "question1": "While defining a business workflow as state machine on AWS Step Functions, a developer has configured several states.",
            "question2": "Which of the following would you identify as the state that represents a single unit of work performed by a state machine?"
        },
        "answers": [
            1
        ],
        "id": 15
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "2.7 TiB"
                },
                {
                    "id": 2,
                    "value": "5.3 TiB"
                },
                {
                    "id": 3,
                    "value": "16 TiB"
                },
                {
                    "id": 4,
                    "value": "10.6 TiB"
                }
            ],
            "question1": "A business has their test environment built on Amazon EC2 configured on General purpose SSD volume.",
            "question2": "At which gp2 volume size will their test environment hit the max IOPS?"
        },
        "answers": [
            2
        ],
        "id": 16
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "AWS CodeBuild"
                },
                {
                    "id": 2,
                    "value": "AWS CodePipeline"
                },
                {
                    "id": 3,
                    "value": "AWS CodeDeploy"
                },
                {
                    "id": 4,
                    "value": "AWS Elastic Beanstalk"
                }
            ],
            "question1": "A developer needs to automate software package deployment to both Amazon EC2 instances and virtual servers running on-premises, as part of continuous integration and delivery that the business has adopted.",
            "question2": "Which AWS service should he use to accomplish this task?"
        },
        "answers": [
            3
        ],
        "id": 17
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Amazon ElastiCache with Amazon S3 as backup"
                },
                {
                    "id": 2,
                    "value": "Amazon Simple Storage Service (Amazon S3) as a direct Firehose destination"
                },
                {
                    "id": 3,
                    "value": "Amazon Elasticsearch Service (Amazon ES) with optionally backing up data to Amazon S3"
                },
                {
                    "id": 4,
                    "value": "Amazon Redshift with Amazon S3"
                }
            ],
            "question1": "A developer working with EC2 Windows instance has installed Kinesis Agent for Windows to stream JSON-formatted log files to Amazon Simple Storage Service (S3) via Amazon Kinesis Data Firehose. The developer wants to understand the sink type capabilities of Kinesis Firehose.",
            "question2": "Which of the following sink types is NOT supported by Kinesis Firehose."
        },
        "answers": [
            1
        ],
        "id": 18
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Configure AWS Web Application Firewall (WAF) to monitor and control the HTTP and HTTPS requests that are forwarded to CloudFront"
                },
                {
                    "id": 2,
                    "value": "Use CloudFront signed URL feature to control access to the file"
                },
                {
                    "id": 3,
                    "value": "Using CloudFront's Field-Level Encryption to help protect sensitive data"
                },
                {
                    "id": 4,
                    "value": "Use CloudFront signed cookies feature to control access to the file"
                }
            ],
            "question1": "A pharmaceutical company uses Amazon EC2 instances for application hosting and Amazon CloudFront for content delivery. A new research paper with critical findings has to be shared with a research team that is spread across the world.",
            "question2": "Which of the following represents the most optimal solution to address this requirement without compromising the security of the content?"
        },
        "answers": [
            2
        ],
        "id": 19
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "To the non-failed instances"
                },
                {
                    "id": 2,
                    "value": "You cannot rollback a CodeDeploy deployment"
                },
                {
                    "id": 3,
                    "value": "To the failed instances"
                },
                {
                    "id": 4,
                    "value": "To the new instances"
                }
            ],
            "question1": "You are a developer handling a deployment service that automates application deployments to Amazon EC2 instances. Most of the deployments consist of code, but sometimes web and configuration files. One of your deployments failed and was rolled back by AWS CodeDeploy to the last known good application revision.",
            "question2": "During rollback which of the following instances did AWS CodeDeploy deploy first to?"
        },
        "answers": [
            3
        ],
        "id": 20
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Application Load Balancer + ECS"
                },
                {
                    "id": 2,
                    "value": "Application Load Balancer + Beanstalk"
                },
                {
                    "id": 3,
                    "value": "Classic Load Balancer + ECS"
                },
                {
                    "id": 4,
                    "value": "Classic Load Balancer + Beanstalk"
                }
            ],
            "question1": "Your company has embraced cloud-native microservices architectures. New applications must be dockerized and stored in a registry service offered by AWS. The architecture should support dynamic port mapping and support multiple tasks from a single service on the same container instance. All services should run on the same EC2 instance.",
            "question2": "Which of the following options offers the best-fit solution for the given use-case?"
        },
        "answers": [
            1
        ],
        "id": 21
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "RDS Maria DB"
                },
                {
                    "id": 2,
                    "value": "RDS Sequel Server"
                },
                {
                    "id": 3,
                    "value": "RDS Oracle"
                },
                {
                    "id": 4,
                    "value": "RDS MySQL"
                },
                {
                    "id": 5,
                    "value": "RDS PostGreSQL"
                }
            ],
            "question1": "The Development team at a media company is working on securing their databases.",
            "question2": "Which of the following AWS database engines can be configured with IAM Database Authentication? (Select two)"
        },
        "answers": [
            4,
            5
        ],
        "id": 22
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Presence of Transform section indicates it is a CloudFormation Parameter"
                },
                {
                    "id": 2,
                    "value": "Presence of Transform section indicates it is a Serverless Application Model (SAM) template"
                },
                {
                    "id": 3,
                    "value": "It represents a Lambda function definition"
                },
                {
                    "id": 4,
                    "value": "It represents an intrinsic function"
                }
            ],
            "question1": "As a Developer, you are given a document written in YAML that represents the architecture of a serverless application. The first line of the document contains Transform: 'AWS::Serverless-2016-10-31'.",
            "question2": "What does the Transform section in the document represent?"
        },
        "answers": [
            2
        ],
        "id": 23
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "You can also use AWS Identity and Access Management (IAM) permissions policies to restrict what the root user can do with CloudFront key pairs"
                },
                {
                    "id": 2,
                    "value": "When you create a signer, the public key is with CloudFront and private key is used to sign a portion of URL"
                },
                {
                    "id": 3,
                    "value": "When you use the root user to manage CloudFront key pairs, you can only have up to two active CloudFront key pairs per AWS account"
                },
                {
                    "id": 4,
                    "value": "Both the signers (trusted key groups and CloudFront key pairs) can be managed using the CloudFront APIs"
                },
                {
                    "id": 5,
                    "value": "CloudFront key pairs can be created with any account that has administrative permissions and full access to CloudFront resources"
                }
            ],
            "question1": "A developer is defining the signers that can create signed URLs for their Amazon CloudFront distributions.",
            "question2": "Which of the following statements should the developer consider while defining the signers? (Select two)"
        },
        "answers": [
            2,
            3
        ],
        "id": 24
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Use dead-letter queues to postpone the delivery of new messages to the queue for a few seconds"
                },
                {
                    "id": 2,
                    "value": "Use FIFO queues to postpone the delivery of new messages to the queue for a few seconds"
                },
                {
                    "id": 3,
                    "value": "Use delay queues to postpone the delivery of new messages to the queue for a few seconds"
                },
                {
                    "id": 4,
                    "value": "Use visibility timeout to postpone the delivery of new messages to the queue for a few seconds"
                }
            ],
            "question1": "The development team at an analytics company is using SQS queues for decoupling the various components of application architecture. As the consumers need additional time to process SQS messages, the development team wants to postpone the delivery of new messages to the queue for a few seconds.",
            "question2": "As a Developer Associate, which of the following solutions would you recommend to the development team?"
        },
        "answers": [
            3
        ],
        "id": 25
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "60"
                },
                {
                    "id": 2,
                    "value": "10"
                },
                {
                    "id": 3,
                    "value": "20"
                },
                {
                    "id": 4,
                    "value": "30"
                }
            ],
            "question1": "As a senior architect, you are responsible for the development, support, maintenance, and implementation of all database applications written using NoSQL technology. A new project demands a throughput requirement of 10 strongly consistent reads per second of 6KB in size each.",
            "question2": "How many read capacity units will you need when configuring your DynamoDB table?"
        },
        "answers": [
            3
        ],
        "id": 26
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "DependentParameter"
                },
                {
                    "id": 2,
                    "value": "CommaDelimitedList"
                },
                {
                    "id": 3,
                    "value": "String"
                },
                {
                    "id": 4,
                    "value": "AWS::EC2::KeyPair::KeyName"
                }
            ],
            "question1": "Your team lead has asked you to learn AWS CloudFormation to create a collection of related AWS resources and provision them in an orderly fashion. You decide to provide AWS-specific parameter types to catch invalid values.",
            "question2": "When specifying parameters which of the following is not a valid Parameter type?"
        },
        "answers": [
            1
        ],
        "id": 27
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Use ConsistentRead = true while doing UpdateItem operation for any item"
                },
                {
                    "id": 2,
                    "value": "Use ConsistentRead = false while doing PutItem operation for any item"
                },
                {
                    "id": 3,
                    "value": "Use ConsistentRead = true while doing GetItem operation for any item"
                },
                {
                    "id": 4,
                    "value": "Use ConsistentRead = true while doing PutItem operation for any item"
                }
            ],
            "question1": "The technology team at an investment bank uses DynamoDB to facilitate high-frequency trading where multiple trades can try and update an item at the same time.",
            "question2": "Which of the following actions would make sure that only the last updated value of any item is used in the application?"
        },
        "answers": [
            3
        ],
        "id": 28
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Use Scan operation"
                },
                {
                    "id": 2,
                    "value": "Batch writes"
                },
                {
                    "id": 3,
                    "value": "Atomic Counters"
                },
                {
                    "id": 4,
                    "value": "Conditional writes"
                }
            ],
            "question1": "A startup has been experimenting with DynamoDB in its new test environment. The development team has discovered that some of the write operations have been overwriting existing items that have the specified primary key. This has messed up their data, leading to data discrepancies.",
            "question2": "Which DynamoDB write option should be selected to prevent this kind of overwriting?"
        },
        "answers": [
            4
        ],
        "id": 29
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Use the Amazon Athena transactional read and write APIs on the table items as a single, all-or-nothing operation"
                },
                {
                    "id": 2,
                    "value": "Use the DynamoDB transactional read and write APIs on the table items as a single, all-or-nothing operation"
                },
                {
                    "id": 3,
                    "value": "Perform DynamoDB read and write operations with ConsistentRead parameter set to true"
                },
                {
                    "id": 4,
                    "value": "Complete both operations on RDS MySQL in a single transaction block"
                },
                {
                    "id": 5,
                    "value": "Complete both operations on Amazon RedShift in a single transaction block"
                }
            ],
            "question1": "A social gaming application supports the transfer of gift vouchers between users. When a user hits a certain milestone on the leaderboard, they earn a gift voucher that can be redeemed or transferred to another user. The development team wants to ensure that this transfer is captured in the database such that the records for both users are either written successfully with the new gift vouchers or the status quo is maintained.",
            "question2": "Which of the following solutions represent the best-fit options to meet the requirements for the given use-case? (Select two)"
        },
        "answers": [
            2,
            4
        ],
        "id": 30
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Parameters"
                },
                {
                    "id": 2,
                    "value": "Mappings"
                },
                {
                    "id": 3,
                    "value": "Transform"
                },
                {
                    "id": 4,
                    "value": "Globals"
                }
            ],
            "question1": "Other than the Resources section, which of the following sections in a Serverless Application Model (SAM) Template is mandatory?"
        },
        "answers": [
            3
        ],
        "id": 31
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "The ASG will keep the instance running and re-start the application"
                },
                {
                    "id": 2,
                    "value": "The ASG will terminate the EC2 Instance"
                },
                {
                    "id": 3,
                    "value": "The ASG will format the root EBS drive on the EC2 instance and run the User Data again"
                },
                {
                    "id": 4,
                    "value": "The ASG will detach the EC2 instance from the group, and leave it running"
                }
            ],
            "question1": "You create an Auto Scaling group to work with an Application Load Balancer. The scaling group is configured with a minimum size value of 5, a maximum value of 20, and the desired capacity value of 10. One of the 10 EC2 instances has been reported as unhealthy.",
            "question2": "Which of the following actions will take place?"
        },
        "answers": [
            2
        ],
        "id": 32
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "ApplicationStart"
                },
                {
                    "id": 2,
                    "value": "ValidateService"
                },
                {
                    "id": 3,
                    "value": "AllowTraffic"
                },
                {
                    "id": 4,
                    "value": "AfterInstall"
                }
            ],
            "question1": "A company uses AWS CodeDeploy to deploy applications from GitHub to EC2 instances running Amazon Linux. The deployment process uses a file called appspec.yml for specifying deployment hooks. A final lifecycle event should be specified to verify the deployment success.",
            "question2": "Which of the following hook events should be used to verify the success of the deployment?"
        },
        "answers": [
            2
        ],
        "id": 33
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Use KMS direct encryption and store as file"
                },
                {
                    "id": 2,
                    "value": "Use Envelope Encryption and store as environment variable"
                },
                {
                    "id": 3,
                    "value": "Use Envelope Encryption and reference the data as file within the code"
                },
                {
                    "id": 4,
                    "value": "Use KMS Encryption and store as environment variable"
                }
            ],
            "question1": "You have launched several AWS Lambda functions written in Java. A new requirement was given that over 1MB of data should be passed to the functions and should be encrypted and decrypted at runtime.",
            "question2": "Which of the following methods is suitable to address the given use-case?"
        },
        "answers": [
            3
        ],
        "id": 34
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Configure the data producer to retry with an exponential backoff"
                },
                {
                    "id": 2,
                    "value": "Use Amazon SQS instead of Kinesis Data Streams"
                },
                {
                    "id": 3,
                    "value": "Use Kinesis enhanced fan-out for Kinesis Data Streams"
                },
                {
                    "id": 4,
                    "value": "Increase the number of shards within your data streams to provide enough capacity"
                },
                {
                    "id": 5,
                    "value": "Use Amazon Kinesis Agent instead of Kinesis Producer Library (KPL) for sending data to Kinesis Data Streams"
                }
            ],
            "question1": "A data analytics company is processing real-time Internet-of-Things (IoT) data via Kinesis Producer Library (KPL) and sending the data to a Kinesis Data Streams driven application. The application has halted data processing because of a ProvisionedThroughputExceeded exception.",
            "question2": "Which of the following actions would help in addressing this issue? (Select two)"
        },
        "answers": [
            1,
            4
        ],
        "id": 35
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "When you send anonymous requests to Amazon Simple Storage Service (Amazon S3)"
                },
                {
                    "id": 2,
                    "value": "When you send HTTP requests to an AWS service"
                },
                {
                    "id": 3,
                    "value": "When you use the AWS Command Line Interface (AWS CLI) to run commands on an AWS resource"
                },
                {
                    "id": 4,
                    "value": "When you use one of the AWS SDKs to make requests to AWS resources/services"
                }
            ],
            "question1": "Signing AWS API requests helps AWS identify an authentic user from a potential threat.",
            "question2": "As a developer associate, which of the following would you identify as the use-case where you need to sign the API requests?"
        },
        "answers": [
            2
        ],
        "id": 36
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "100000"
                },
                {
                    "id": 2,
                    "value": "no limit"
                },
                {
                    "id": 3,
                    "value": "10000"
                },
                {
                    "id": 4,
                    "value": "10000000"
                }
            ],
            "question1": "A company has a cloud system in AWS with components that send and receive messages using SQS queues. While reviewing the system you see that it processes a lot of information and would like to be aware of any limits of the system.",
            "question2": "Which of the following represents the maximum number of messages that can be stored in an SQS queue?"
        },
        "answers": [
            2
        ],
        "id": 37
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Use the DynamoDB on-demand backup capability to write to Amazon S3 and download locally"
                },
                {
                    "id": 2,
                    "value": "Use AWS Glue to copy your table to Amazon S3 and download locally"
                },
                {
                    "id": 3,
                    "value": "Use Hive with Amazon EMR to export your data to an S3 bucket and download locally"
                },
                {
                    "id": 4,
                    "value": "Use AWS Data Pipeline to export your table to an S3 bucket in the account of your choice and download locally"
                }
            ],
            "question1": "A diagnostic lab stores its data on DynamoDB. The lab wants to backup a particular DynamoDB table data on Amazon S3, so it can download the S3 backup locally for some operational use.",
            "question2": "Which of the following options is NOT feasible?"
        },
        "answers": [
            1
        ],
        "id": 38
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Enable S3 and CloudWatch Logs integration"
                },
                {
                    "id": 2,
                    "value": "Use AWS Lambda integration"
                },
                {
                    "id": 3,
                    "value": "Use CloudWatch Events"
                },
                {
                    "id": 4,
                    "value": "Use AWS CloudTrail and deliver logs to S3"
                }
            ],
            "question1": "As a Team Lead, you are expected to generate a report of the code builds for every week to report internally and to the client. This report consists of the number of code builds performed for a week, the percentage success and failure, and overall time spent on these builds by the team members. You also need to retrieve the CodeBuild logs for failed builds and analyze them in Athena.",
            "question2": "Which of the following options will help achieve this?"
        },
        "answers": [
            1
        ],
        "id": 39
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "dynamodb:UpdateItem, dynamodb:GetItem, dynamodb:PutItem"
                },
                {
                    "id": 2,
                    "value": "dynamodb:AddItem, dynamodb:GetItem"
                },
                {
                    "id": 3,
                    "value": "dynamodb:UpdateItem, dynamodb:GetItem"
                },
                {
                    "id": 4,
                    "value": "dynamodb:GetRecords, dynamodb:PutItem, dynamodb:UpdateTable"
                }
            ],
            "question1": "A development team is working on an AWS Lambda function that accesses DynamoDB. The Lambda function must do an upsert, that is, it must retrieve an item and update some of its attributes or create the item if it does not exist.",
            "question2": "Which of the following represents the solution with MINIMUM IAM permissions that can be used for the Lambda function to achieve this functionality?"
        },
        "answers": [
            3
        ],
        "id": 40
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Capture the transactions in the players table using DynamoDB streams and then sync with the items table"
                },
                {
                    "id": 2,
                    "value": "Use BatchWriteItem API to update multiple tables simultaneously"
                },
                {
                    "id": 3,
                    "value": "Use TransactWriteItems API of DynamoDB Transactions"
                },
                {
                    "id": 4,
                    "value": "Capture the transactions in the items table using DynamoDB streams and then sync with the players table"
                }
            ],
            "question1": "A development team is building a game where players can buy items with virtual coins. For every virtual coin bought by a user, both the players table as well as the items table in DynamodDB need to be updated simultaneously using an all-or-nothing operation.",
            "question2": "As a developer associate, how will you implement this functionality?"
        },
        "answers": [
            3
        ],
        "id": 41
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "!Param"
                },
                {
                    "id": 2,
                    "value": "!GetAtt"
                },
                {
                    "id": 3,
                    "value": "!Join"
                },
                {
                    "id": 4,
                    "value": "!Ref"
                }
            ],
            "question1": "A team lead has asked you to create an AWS CloudFormation template that creates EC2 instances and RDS databases. The template should be reusable by allowing the user to input a parameter value for an Amazon EC2 AMI ID.",
            "question2": "Which of the following intrinsic function should you choose to reference the parameter?"
        },
        "answers": [
            4
        ],
        "id": 42
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Define an appspec.yml file in the codebuild/ directory"
                },
                {
                    "id": 2,
                    "value": "Define a buildspec.yml file in the codebuild/ directory"
                },
                {
                    "id": 3,
                    "value": "Define an appspec.yml file in the root directory"
                },
                {
                    "id": 4,
                    "value": "Define a buildspec.yml file in the root directory"
                }
            ],
            "question1": "A developer in your company was just promoted to Team Lead and will be in charge of code deployment on EC2 instances via AWS CodeCommit and AWS CodeDeploy. Per the new requirements, the deployment process should be able to change permissions for deployed files as well as verify the deployment success.",
            "question2": "Which of the following actions should the new Developer take?"
        },
        "answers": [
            3
        ],
        "id": 43
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "AWS CodeCommit"
                },
                {
                    "id": 2,
                    "value": "Amazon Versioned S3 Bucket"
                },
                {
                    "id": 3,
                    "value": "AWS CodePipeline"
                },
                {
                    "id": 4,
                    "value": "AWS CodeBuild"
                }
            ],
            "question1": "A company needs a version control system for their fast development lifecycle with incremental changes, version control, and support to existing Git tools.",
            "question2": "Which AWS service will meet these requirements?"
        },
        "answers": [
            1
        ],
        "id": 44
    },
    {
        "en": {
            "options": [
                {
                    "id": 1,
                    "value": "Public-facing Application Load Balancer with ECS on Amazon EC2"
                },
                {
                    "id": 2,
                    "value": "Fargate with Lambda at the front"
                },
                {
                    "id": 3,
                    "value": "Route 53 with EC2 as backend"
                },
                {
                    "id": 4,
                    "value": "API Gateway exposing Lambda Functionality"
                }
            ],
            "question1": "As an AWS Certified Developer Associate, you have been hired to work with the development team at a company to create a REST API using the serverless architecture.",
            "question2": "Which of the following solutions will you choose to move the company to the serverless architecture paradigm?"
        },
        "answers": [
            4
        ],
        "id": 45
    }
]